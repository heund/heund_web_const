<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hee-Eun Kim | Under Construction</title>
  <style>
    body {
      margin: 0;
      min-height: 100vh;
      overflow-x: hidden;
      cursor: default;
      padding: 15px;
      padding-bottom: 60px; /* Space for mobile banner */
      position: relative;
      -webkit-text-size-adjust: 100%;
      -webkit-font-smoothing: antialiased;
      box-sizing: border-box;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
      line-height: 1.6;
      font-size: 18px;
      max-width: 800px;
      margin: 0 auto;
    }
    html {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }
    h1 {
      font-size: 32px;
      margin-top: 24px;
      margin-bottom: 16px;
    }
    h2 {
      font-size: 28px;
      margin-top: 30px;
      margin-bottom: 18px;
      border-bottom: 1px solid #eee;
      padding-bottom: 8px;
    }
    h3 {
      font-size: 24px;
      margin-top: 24px;
      margin-bottom: 12px;
    }
    ul {
      padding-left: 30px;
    }
    li {
      margin-bottom: 10px;
    }
    p {
      margin-top: 10px;
      margin-bottom: 20px;
    }
    .work-description {
      margin-left: 20px;
      margin-bottom: 18px;
      font-size: 18px;
      line-height: 1.7;
    }
    .work-specs {
      margin-left: 20px;
      margin-bottom: 24px;
      font-style: italic;
      color: #555;
      font-size: 16px;
    }
    .work-title {
      margin-bottom: 6px;
      font-size: 20px;
    }
    .work-venue {
      margin-left: 10px;
      margin-bottom: 12px;
      font-weight: normal;
      font-size: 18px;
    }
    .tagline {
      font-size: 20px;
      color: #555;
      margin-top: 5px;
      margin-bottom: 15px;
      font-style: italic;
      font-weight: normal;
    }
    .bg-text {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%) rotate(-15deg);
      font-size: 15vw;
      font-weight: bold;
      color: rgba(200, 200, 200, 0.2);
      white-space: nowrap;
      pointer-events: none;
      z-index: -1;
      user-select: none;
      transition: transform 0.1s ease-out;
      will-change: transform;
      word-break: break-word;
      white-space: normal;
      text-align: center;
      padding: 0 20px;
      box-sizing: border-box;
      width: 100%;
    }
    .content {
      position: relative;
      z-index: 1;
      transition: opacity 0.3s ease;
    }
    .content.animations-disabled .falling-text {
      pointer-events: none !important;
    }
    /* Mobile banner - always visible */
    .mobile-banner {
      display: block;
      position: fixed;
      bottom: 0;
      left: 0;
      width: 100%;
      background: #000;
      color: white;
      text-align: center;
      padding: 15px 0;
      font-family: monospace;
      font-size: 14px;
      z-index: 1000;
      box-shadow: 0 -2px 10px rgba(0,0,0,0.1);
    }
    
    /* Hide the interactive button on mobile */
    .opt-out-btn {
      display: none;
    }
    
    @media (min-width: 768px) {
      body {
        padding-bottom: 15px; /* Reset padding for desktop */
      }
      /* Hide mobile banner on desktop */
      .mobile-banner {
        display: none;
      }
      
      /* Show and style the interactive button for desktop */
      .opt-out-btn {
        position: fixed;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        top: 50%;
        right: 0;
        bottom: auto;
        width: auto;
        height: auto;
        background: #f0f0f0;
        border: 1px solid #ccc;
        border-radius: 4px;
        padding: 8px 16px;
        margin: 0;
        cursor: pointer;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        font-size: 14px;
        font-weight: normal;
        text-align: center;
        color: #333;
        z-index: 1000;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: background-color 0.2s ease, border-color 0.2s ease;
        text-transform: none;
        transform: translateY(-50%);
      }
      
      .opt-out-btn .close-icon {
        font-size: 16px;
        font-weight: normal;
        margin-bottom: 4px;
        display: block;
        line-height: 1;
      }
      
      .opt-out-btn:hover {
        background: #e0e0e0;
        border-color: #999;
      }
    }
    .opt-out-btn:hover {
      background: #000;
      color: white;
    }
    .close-icon {
      font-size: 24px;
      font-weight: bold;
      margin-bottom: 0;
      transition: transform 0.3s ease;
    }
    .falling-text {
      display: inline-block;
      transition: all 0.5s ease-out;
      transform-origin: top center;
    }
  </style>
  <script>
    function wrapTextNodes(element) {
      const walker = document.createTreeWalker(
        element,
        NodeFilter.SHOW_TEXT,
        null,
        false
      );
      
      const textNodes = [];
      let node;
      while (node = walker.nextNode()) {
        if (node.nodeValue.trim() !== '') {
          textNodes.push(node);
        }
      }
      
      textNodes.forEach(textNode => {
        const wrapper = document.createElement('span');
        wrapper.className = 'falling-text';
        textNode.parentNode.insertBefore(wrapper, textNode);
        wrapper.appendChild(textNode);
      });
    }
    
    let animationsEnabled = true;
    
    function toggleAnimations() {
      animationsEnabled = !animationsEnabled;
      const content = document.querySelector('.content');
      const btn = document.querySelector('.opt-out-btn');
      
      if (animationsEnabled) {
        content.classList.remove('animations-disabled');
        btn.textContent = 'Opt Out of Disintegration';
        btn.innerHTML = '<span class="close-icon">&times;</span> ' + btn.textContent;
      } else {
        content.classList.add('animations-disabled');
        btn.textContent = 'Enable Disintegration';
        btn.innerHTML = '<span class="close-icon">&#x21bb;</span> ' + btn.textContent;
      }
      
      // Save preference
      localStorage.setItem('animationsEnabled', animationsEnabled);
    }
    
    function addHoverEffects() {
      const elements = document.querySelectorAll('.falling-text');
      
      elements.forEach(el => {
        // Skip if already processed
        if (el.dataset.processed) return;
        el.dataset.processed = 'true';
        
        el.addEventListener('mouseenter', (e) => {
          if (!animationsEnabled) return;
          // Random direction and rotation
          const angle = (Math.random() * 60 - 30); // -30 to 30 degrees
          const distance = 100 + Math.random() * 100; // 100-200px
          const rotation = (Math.random() * 40 - 20); // -20 to 20 degrees
          
          e.target.style.transform = `translateY(${distance}px) rotate(${rotation}deg)`;
          e.target.style.opacity = '0';
          
          // Reset after animation
          setTimeout(() => {
            e.target.style.transition = 'none';
            e.target.style.transform = 'translateY(-100px) rotate(0deg)';
            e.target.style.opacity = '0';
            
            // Force reflow
            void e.target.offsetWidth;
            
            // Restore transition and reset position
            e.target.style.transition = 'all 0.5s ease-out';
            e.target.style.transform = '';
            e.target.style.opacity = '';
          }, 500);
        });
      });
    }
    // Easter egg for console
    console.log(
      `%c´´´´¶¶¶¶¶¶´´´´´´¶¶¶¶¶
´´¶¶¶¶¶¶¶¶´´´¶¶¶¶¶¶¶¶¶
´¶¶¶¶¶¶¶¶¶¶´¶¶¶¶´´´´¶¶¶¶
¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶´´´´¶¶¶
¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶´´¶¶¶¶
¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶ ´¶¶¶¶´
´´¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶
´´´´´¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶
´´´´´´´¶¶¶¶¶¶¶¶¶¶¶¶
´´´´´´´´´¶¶¶¶¶¶¶¶
´´´´´´´´´´´¶¶¶¶
%cWhat if you can %cFEEL%c systems?`,
      'font-family: monospace; font-size: 12px; line-height: 1; color: #ff6b6b;',
      'font-weight: bold;',
      'font-weight: bold; color: #ff0000;',
      'font-weight: normal;'
    );
    console.log('%c- Hee-Eun Kim (Bekkie)', 'font-style: italic; color: #666;');

    document.addEventListener('DOMContentLoaded', () => {
      // Create and add the opt-out button (only for desktop)
      let optOutBtn = null;
      if (window.innerWidth >= 768) {
        optOutBtn = document.createElement('div');
        optOutBtn.className = 'opt-out-btn';
        optOutBtn.innerHTML = '<span class="close-icon">&times;</span><span>Opt Out of Disintegration</span>';
        document.body.appendChild(optOutBtn);
      }
      
      // Load animation preference
      if (localStorage.getItem('animationsEnabled') === 'false') {
        animationsEnabled = false;
        document.querySelector('.content').classList.add('animations-disabled');
        if (optOutBtn) {
          optOutBtn.innerHTML = '<span class="close-icon">↻</span><span>Enable Disintegration</span>';
        }
      }
      
      // Add click handler for the button if it exists
      if (optOutBtn) {
        optOutBtn.addEventListener('click', toggleAnimations);
      }
      
      // Wrap all text nodes in the content div
      const content = document.querySelector('.content');
      wrapTextNodes(content);
      addHoverEffects();
      
      const bgText = document.querySelector('.bg-text');
      const sensitivity = 0.02; // Adjust this value to control the movement intensity
      
      // Handle both mouse and touch movement
      const handleMove = (e) => {
        let clientX, clientY;
        
        if (e.touches) {
          // Handle touch events
          clientX = e.touches[0].clientX;
          clientY = e.touches[0].clientY;
        } else {
          // Handle mouse events
          clientX = e.clientX;
          clientY = e.clientY;
        }
        
        // Get position as percentage (0-1)
        const x = clientX / window.innerWidth - 0.5;
        const y = (clientY / window.innerHeight - 0.5) * -1; // Invert Y axis
        
        // Calculate movement (smaller on mobile)
        const moveAmount = window.innerWidth >= 768 ? 100 : 30;
        const moveX = x * sensitivity * moveAmount;
        const moveY = y * sensitivity * moveAmount;
        
        // Apply movement with smooth transition
        bgText.style.transform = `translate(calc(-50% + ${moveX}px), calc(-50% + ${moveY}px)) rotate(-15deg)`;
      };
      
      // Only add event listeners if not on mobile
      if (window.innerWidth >= 768) {
        document.addEventListener('mousemove', handleMove);
      }
      document.addEventListener('touchmove', handleMove, { passive: true });
      
      // Reset position when mouse/touch leaves
      const resetPosition = () => {
        bgText.style.transform = 'translate(-50%, -50%) rotate(-15deg)';
      };
      
      document.addEventListener('mouseleave', resetPosition);
      document.addEventListener('touchend', resetPosition, { passive: true });
      
      // Prevent zoom on double-tap
      document.addEventListener('dblclick', (e) => {
        e.preventDefault();
      }, { passive: false });
    });
  </script>
</head>
<body>
  <div class="bg-text">Under Construction</div>
  <div class="mobile-banner">Website Under Construction</div>
  <div class="content">
  <h1>Hee-Eun Kim (Bekkie) | h.eund</h1>
  <div class="tagline">Artist-Researcher developing relational systems and participatory sound environments</div>
  <p>Artist-Researcher | Systems Designer | Participatory Sound</p>
  <hr>
  
  <h2>About</h2>
  <p class="work-description">
    Hee-Eun Kim (Bekkie) is a South Korean artist-researcher whose work develops non-extractive, relational systems for making complex environmental and social processes perceptible through sound, movement, and shared interaction. Her practice reframes data not as static representation but as a living, negotiated field that emerges through listening, collaboration, and collective presence.
  </p>
  <p class="work-description">
    Drawing on systems theory, environmental science, and Eastern philosophy, Hee-Eun creates frameworks that hold complexity and contradiction rather than reduce them. She integrates local knowledge with empirical data, designing participatory installations that invite audiences to inhabit interdependencies and engage with hidden dynamics. These projects include mapping heavy metal contamination as sonic terrain, reimagining emotion recognition as shared ritual, and transforming vibration data into improvisational jazz.
  </p>
  <p class="work-description">
    Hee-Eun's work foregrounds ethical methodologies for community collaboration and interdisciplinary research. Her projects include the development of Behaviour-Driven Systemic Sonification (BDSS), a generative framework modelling environmental systems as evolving sonic fields, and the Relational Cognitive System (RCS), which explores co-regulated, affect-sensitive interaction between humans and AI.
  </p>
  
  <h2>Research</h2>
  <p class="work-description">
    <a href="https://doi.org/10.5281/zenodo.15509042" target="_blank">BDSS Prototype Implementation: A Behavioural Approach to Sonifying Photosynthetic Systems</a> (2025)
  </p>
  
  <h2>Works</h2>
  
  <h3>Grants & Fellowships</h3>
  <ul>
    <li class="work-title">2024 – <b>DNA Art Lab</b></li>
  </ul>
  <div class="work-venue">Pohang Culture Foundation, Pohang, South Korea</div>
  
  <h3>Selected Exhibitions & Performances</h3>
  <ul>
    <li class="work-title">2025 – <b>Void && Form</b></li>
  </ul>
  <div class="work-venue">Das LOT, Vienna, Austria (Team Mangshinsal)</div>
  <p class="work-description">
    Interactive installation examining the ethics of affective data through real-time emotion recognition.<br><br>
    Participants' faces are mirrored as digital twins on-screen, set against a large mandala backdrop evoking Buddhist philosophies of impermanence and interdependence. Responsive soundscapes shift with emotional states, rendering private affect as a shared, dynamic environment.<br><br>
    The work invites a contemplative negotiation of selfhood, surveillance, and non-extractive witnessing, transforming observation into an encounter with relational presence.
  </p>
  <div class="work-specs">FaceAPI, Webcam, LED Display – Dimensions Variable</div>
  
  <ul>
    <li class="work-title">2024 – <b>Metal Rave</b></li>
  </ul>
  <div class="work-venue">Dongbin 1969, Pohang, South Korea</div>
  <p class="work-description">
    Immersive installation translating heavy metal contamination data from the Hyungsan River Basin into navigable sonic cartographies.<br><br>
    Audiences move through projected digital maps while industrial soundscapes expose hidden toxic flows beneath the landscape's surface. By fusing environmental data with visceral sound, the work critiques extractive practices and challenges viewers to confront contamination not as abstract measurement but as lived, material consequence.
  </p>
  <div class="work-specs">4.1 Channel Sound System, Conveyor Belt, LED Display, Joystick – Dimensions Variable</div>
  
  <ul>
    <li class="work-title">2024 – <b>Sonification of Soil Contamination Data</b></li>
  </ul>
  <div class="work-venue">Solar Happy Hour, Songpa Library, Seoul, South Korea</div>
  <p class="work-description">
    Sound piece translating soil contamination data from the Korean Ministry of Environment into immersive sonic environments layered with improvised traditional Korean instruments.<br><br>
    By fusing empirical data with cultural sound forms, the work renders the heaviness of environmental pollution as an embodied, shared listening experience. It invites audiences to confront toxicity not as distant abstraction but as a felt, cultural memory, bridging scientific measurement with interpretive storytelling to surface hidden ecological burdens.
  </p>
  <div class="work-specs">Max/MSP, Media Wall</div>
  
  <ul>
    <li class="work-title">2024 – <b>Deviated Vibrations</b></li>
  </ul>
  <div class="work-venue">(Collaboration with Pohang Accelerator Laboratory), Art & Tech Cluster Forum, Pohang, South Korea</div>
  <p class="work-description">
    Generative sound work transforming anomaly detection data from the accelerator into an improvised jazz composition.<br><br>
    By mathematically modelling the erratic patterns of beamline vibrations as jazz riffs, the piece reimagines scientific irregularities as creative departures rather than errors. This interpretive translation invites listeners to hear complexity and unpredictability not as noise to be corrected but as the basis for new forms of meaning, bridging technical measurement with musical improvisation.
  </p>
  <div class="work-specs">Max/MSP, Ableton Live</div>
  
  <ul>
    <li class="work-title">2024 – <b>!Mediengruppe Bitnik 4X4, Seoul Edition</b></li>
  </ul>
  <div class="work-venue">Arko Art Centre & Gwangju Biennale, Gwangju, South Korea</div>
  <p class="work-description">
    Performed as The Shot within !Mediengruppe Bitnik's 4X4, a programme pairing artists meeting for the first time to co-create new work over four days.<br><br>
    The performance examined sound's infiltration of everyday space through layered assemblages of objects, images, and audio, activating these elements to transform material meaning and reveal subtle narrative structures embedded within familiar environments.
  </p>
  
  
  <h2>Experiments</h2>
  <p class="work-description">
    <b>Data Model Sonification Series</b><br>
    A comparative sound experiment exploring how different cognitive and informational models can convey emotional ambiguity and complexity. This series includes:
    <ul>
      <li>Neural Net Approximation</li>
      <li>CLARION Dual-Process Model</li>
      <li>Temporal Pattern Recognition</li>
      <li>Information Theory Model</li>
    </ul>
  </p>
  
  <p class="work-description">
    <b>Relational Cognitive System (RCS)</b><br>
    A novel framework for designing cognitive systems that prioritise relational emergence over computational optimisation. RCS reconceptualises cognition not as input–output processing within isolated agents but as a distributed, negotiated process arising in dynamic relational fields.
  </p>
  <p class="work-description">
    Drawing on systems theory, dynamic systems theory, and Eastern philosophy, RCS models cognition as emergent from recursive symbolic interaction, affective entrainment, and coherence-seeking negotiation. Rather than treating meaning as a static output, it emphasises symbolic anchoring, emotional field modulation, and improvisational adaptation as essential mechanisms of cognitive stability.
  </p>
  <p class="work-description">
    RCS architectures employ multi-agent systems, recursive feedback, and resonance-based evaluation to model cognition as evolving negotiation among distributed inputs, memory traces, and environmental conditions. This approach enables systems capable of co-creating meaning with human participants, supporting affect-sensitive, ethical, and participatory interaction design.
  </p>
  <p class="work-description">
    Implemented in projects such as Behaviour-Driven Systemic Sonification (BDSS), RCS demonstrates its principles through real-time modelling of plant adaptation, distributed emotional intelligence systems, and experimental human–AI interfaces. It offers practical methodologies for affective computing, symbolic reasoning, and collaborative interaction design that seek to think with rather than for human participants.
  </p>
  
  <p class="work-description">
    <b><a href="https://youtube.com/shorts/Oj1zINkZP9A?si=sTNM6e0tUNo1nXAA" target="_blank">Echo Chamber</a></b><br>
    An ongoing experimental interface applying the principles of the Relational Cognitive System (RCS) to affective computing. Rather than offering answers or interpretation, Echo Chamber creates space for complexity by engaging the participant's voice through four artificial emotional agents, each mapped to neurological functions: Amygdala (fear and urgency), Insula (embodied intuition), Prefrontal Cortex (regulation), and Hypothalamus (primal complexity).
  </p>
  <p class="work-description">
    When a participant speaks, these agents respond not by analysing sentiment or providing solutions, but by witnessing what is said, what is left unsaid, and the spaces in between. This interaction generates an emergent emotional field rather than a fixed output, modelling behaviour that arises through ongoing negotiation and adaptation rather than programmed responses.
  </p>
  <p class="work-description">
    Echo Chamber demonstrates RCS philosophies in practice: sound as evidence of relational negotiation, systems designed for co-regulated, affect-sensitive interaction, and behaviours that emerge unpredictably from dynamic interdependencies. Each encounter is ephemeral, storing nothing, dissolving once complete. By rejecting archival extraction, the system challenges conventional AI tendencies and reframes presence as a shared, transient constellation of meaning.
  </p>
  
  <p class="work-description">
    <b>Behaviour-Driven Systemic Sonification (BDSS)</b><br>
    A novel sonification methodology that moves beyond reductive input–output mapping to model the adaptive negotiation inherent in complex systems. Rather than translating discrete data points into fixed sonic parameters, BDSS approaches sound as the emergent expression of systemic behaviour unfolding in real time.
  </p>
  <p class="work-description">
    BDSS conceptualises environmental or physiological processes as trajectories within dynamic attractor spaces, where states are characterised by overlapping, fuzzy boundaries instead of binary classifications. Agent-based negotiation layers simulate the balancing of competing pressures, producing sonic textures that embody tension, adaptation, and feedback.
  </p>
  <p class="work-description">
    Within this framework, sound becomes evidence of a system's capacity to negotiate internal and external forces, revealing the subtle logics through which stability, change, and coherence are continuously redefined. By reframing sonification as an articulation of relational negotiation rather than static representation, BDSS enables the perceptual exploration of hidden dynamics in a form that invites interpretation, critical listening, and ethical engagement with complexity.
  </p>
  
  <p class="work-description">
    <b><a href="https://youtu.be/TRb-llECHgI?si=z7isKYx6ps3podtV" target="_blank">Photosynthesis as Generative Sound: Hearing Plant Conversations</a></b><br>
    An applied BDSS experiment modelling the adaptive negotiation dynamics of a C3 plant across a compressed diurnal cycle. The system represents the plant's physiological state as a continuously shifting point within a three-dimensional vector space defined by light intensity (PAR), temperature, and water potential. This space is structured with overlapping attractor zones—rest, recovery, stress, and critical—whose fuzzy boundaries capture transitional states rather than enforcing binary classifications.
  </p>
  <p class="work-description">
    Negotiation within this model is enacted through three virtual agents with distinct roles. Agent A modulates core frequency, managing systemic balance and tension. Agent B adjusts harmonic intervals in real time based on a coherence metric, responding to changes in system stability. Agent C functions as a memory layer, recalling or repeating motifs when significant state changes occur.
  </p>
  <p class="work-description">
    These agent interactions are rendered as granular synthesis textures, with harmonic guidance rules shifting in real time to reflect varying levels of systemic coherence. Real-time sensor or MIDI inputs allow external modulation of environmental parameters, inducing stress or testing recovery. Visualisations in TouchDesigner map attractor space coordinates and coherence metrics to generative particle fields, making the negotiation process intuitively perceivable.
  </p>
  <p class="work-description">
    This experiment treats sound not as a direct translation of data but as the emergent signal of an ongoing negotiation between environmental pressures and internal adaptive responses, offering new ways to perceive and understand systemic behaviour.
  </p>
  
  <hr>
  
  <p>
    hello[at]heund.net | 
    <a href="https://www.instagram.com/h.eund/" target="_blank" rel="noopener">Instagram</a> | 
    <a href="https://x.com/h_eund" target="_blank" rel="noopener">Twitter</a> |
    <a href="https://www.youtube.com/@heund" target="_blank" rel="noopener">YouTube</a>
  </p>
  
  <p><small>Inspired by the World Wide Web's first page, 1991.</small></p>
  </div>
</body>
</html>
